{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os, math, random, json\n",
        "import numpy as np\n",
        "import scipy.signal as signal\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "T1u2N-g_wvi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reproducibility & device\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkvJk9Tlw2Ky",
        "outputId": "0b559e6d-7357-49b6-b2ea-cef2662953bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Synthetic multivariate generator\n",
        "def generate_synthetic_multivariate(T=5000, n_series=3, noise_std=0.25):\n",
        "    t = np.arange(T)\n",
        "    trend = 0.00002 * (t - T / 2) ** 2 + 0.00015 * t\n",
        "    s1 = 2.0 * np.sin(2 * np.pi * t / 50.0)\n",
        "    s2 = 0.9 * np.cos(2 * np.pi * t / 200.0 + 0.3)\n",
        "    s3 = 0.4 * np.sin(2 * np.pi * t / 7.0)\n",
        "    base = trend + s1 + s2 + s3\n",
        "\n",
        "    temp = 10 + 8 * np.sin(2 * np.pi * t / 365.0) + 0.6 * np.sin(2 * np.pi * t / 30.0)\n",
        "    holiday = (signal.square(2 * np.pi * t / 180.0, duty=0.02) + 1) / 2\n",
        "    exog = np.stack([temp, holiday], axis=1).astype(np.float32)\n",
        "\n",
        "    X = np.zeros((T, n_series), dtype=np.float32)\n",
        "    for i in range(n_series):\n",
        "        a = 1.0 + 0.2 * i\n",
        "        b_temp = 0.05 * (i + 1)\n",
        "        b_hol = 0.8 * (0.5 if i == 0 else (0.3 * (i + 1)))\n",
        "        kernel = np.exp(-np.linspace(0, 3, 30) * (0.5 + 0.15 * i))\n",
        "        interaction = np.convolve(base, kernel, mode='same')[:T]\n",
        "        series = a * interaction + b_temp * temp + b_hol * holiday\n",
        "        noise = noise_std * (1 + 0.4 * np.sin(2 * np.pi * t / 120.0)) * np.random.randn(T)\n",
        "        X[:, i] = series + noise\n",
        "    return X.astype(np.float32), exog"
      ],
      "metadata": {
        "id": "mPhzuYbbw3Sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "class Seq2SeqDataset(Dataset):\n",
        "    def __init__(self, data, exog, input_len, output_len, scaler=None):\n",
        "        assert data.shape[0] == exog.shape[0]\n",
        "        self.data = data\n",
        "        self.exog = exog\n",
        "        self.input_len = input_len\n",
        "        self.output_len = output_len\n",
        "        self.T = data.shape[0]\n",
        "        self.n_series = data.shape[1]\n",
        "        self.n_exog = exog.shape[1]\n",
        "\n",
        "        if scaler is None:\n",
        "            self.scaler = StandardScaler()\n",
        "            self.scaler.fit(self.data)\n",
        "        else:\n",
        "            self.scaler = scaler\n",
        "        self.data_scaled = self.scaler.transform(self.data)\n",
        "\n",
        "        self.starts = list(range(0, self.T - (input_len + output_len) + 1))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.starts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        s = self.starts[idx]\n",
        "        x = self.data_scaled[s:s+self.input_len]            # (input_len, n_series)\n",
        "        y = self.data_scaled[s+self.input_len:s+self.input_len+self.output_len]  # (output_len, n_series)\n",
        "        ex = self.exog[s:s+self.input_len+self.output_len]  # (input_len+output_len, n_exog)\n",
        "        return {\n",
        "            'x': torch.tensor(x, dtype=torch.float32),\n",
        "            'y': torch.tensor(y, dtype=torch.float32),\n",
        "            'ex': torch.tensor(ex, dtype=torch.float32)\n",
        "        }"
      ],
      "metadata": {
        "id": "ZnlwaL_ExGci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Positional encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=20000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
        "        self.register_buffer('pe', pe)\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:, :x.size(1), :]"
      ],
      "metadata": {
        "id": "JsIcdAr4xSXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention / FF / Layers\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        assert d_model % n_heads == 0\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.d_k = d_model // n_heads\n",
        "\n",
        "        self.q_linear = nn.Linear(d_model, d_model)\n",
        "        self.k_linear = nn.Linear(d_model, d_model)\n",
        "        self.v_linear = nn.Linear(d_model, d_model)\n",
        "        self.out = nn.Linear(d_model, d_model)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        B = q.size(0)\n",
        "        Q = self.q_linear(q).view(B, -1, self.n_heads, self.d_k).transpose(1,2)\n",
        "        K = self.k_linear(k).view(B, -1, self.n_heads, self.d_k).transpose(1,2)\n",
        "        V = self.v_linear(v).view(B, -1, self.n_heads, self.d_k).transpose(1,2)\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "        attn = self.dropout(attn)\n",
        "        context = torch.matmul(attn, V)\n",
        "        context = context.transpose(1,2).contiguous().view(B, -1, self.d_model)\n",
        "        out = self.out(context)\n",
        "        return out, attn\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(d_ff, d_model)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadSelfAttention(d_model, n_heads, dropout)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "    def forward(self, x, src_mask=None):\n",
        "        attn_out, attn_w = self.self_attn(x, x, x, mask=src_mask)\n",
        "        x = self.norm1(x + self.drop(attn_out))\n",
        "        ff = self.ff(x)\n",
        "        x = self.norm2(x + self.drop(ff))\n",
        "        return x, attn_w\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadSelfAttention(d_model, n_heads, dropout)\n",
        "        self.cross_attn = MultiHeadSelfAttention(d_model, n_heads, dropout)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "    def forward(self, x, enc_out, src_mask=None, tgt_mask=None):\n",
        "        attn_out, self_w = self.self_attn(x, x, x, mask=tgt_mask)\n",
        "        x = self.norm1(x + self.drop(attn_out))\n",
        "        cross_out, cross_w = self.cross_attn(x, enc_out, enc_out, mask=src_mask)\n",
        "        x = self.norm2(x + self.drop(cross_out))\n",
        "        ff = self.ff(x)\n",
        "        x = self.norm3(x + self.drop(ff))\n",
        "        return x, self_w, cross_w"
      ],
      "metadata": {
        "id": "OcHrjrWVxWWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformer Seq2Seq\n",
        "class TransformerTimeSeries(nn.Module):\n",
        "    def __init__(self, n_series, n_exog, d_model=128, n_heads=4, n_enc_layers=3, n_dec_layers=3, d_ff=256, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.input_proj = nn.Linear(n_series + n_exog, d_model)\n",
        "        self.output_proj = nn.Linear(d_model, n_series)\n",
        "        self.pos_enc = PositionalEncoding(d_model)\n",
        "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_enc_layers)])\n",
        "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_dec_layers)])\n",
        "    def forward(self, src_series, src_exog, tgt_series, tgt_exog, src_mask=None, tgt_mask=None):\n",
        "        batch = src_series.size(0)\n",
        "        src_len = src_series.size(1)\n",
        "        tgt_len = tgt_series.size(1)\n",
        "\n",
        "        src_ex = src_exog[:, :src_len, :]\n",
        "        tgt_ex = tgt_exog[:, src_len:src_len+tgt_len, :]\n",
        "\n",
        "        enc_in = torch.cat([src_series, src_ex], dim=-1)\n",
        "        dec_in = torch.cat([tgt_series, tgt_ex], dim=-1)\n",
        "\n",
        "        enc = self.input_proj(enc_in)\n",
        "        dec = self.input_proj(dec_in)\n",
        "\n",
        "        enc = self.pos_enc(enc)\n",
        "        dec = self.pos_enc(dec)\n",
        "\n",
        "        enc_attns = []\n",
        "        for layer in self.encoder_layers:\n",
        "            enc, attw = layer(enc, src_mask)\n",
        "            enc_attns.append(attw)\n",
        "\n",
        "        dec_self_attns = []\n",
        "        dec_cross_attns = []\n",
        "        for layer in self.decoder_layers:\n",
        "            dec, self_w, cross_w = layer(dec, enc, src_mask, tgt_mask)\n",
        "            dec_self_attns.append(self_w)\n",
        "            dec_cross_attns.append(cross_w)\n",
        "\n",
        "        out = self.output_proj(dec)\n",
        "        return out, {'enc_attns': enc_attns, 'dec_self_attns': dec_self_attns, 'dec_cross_attns': dec_cross_attns}"
      ],
      "metadata": {
        "id": "KoW-0KM-xbuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility: masks & metrics\n",
        "def create_causal_mask(tgt_len, device):\n",
        "    # returns boolean mask shape (1,1,tgt_len,tgt_len)\n",
        "    tri = torch.tril(torch.ones((tgt_len, tgt_len), dtype=torch.bool, device=device))\n",
        "    return tri\n",
        "\n",
        "def rmse(pred, true):\n",
        "    return float(np.sqrt(np.mean((pred - true)**2)))\n",
        "\n",
        "def mae(pred, true):\n",
        "    return float(np.mean(np.abs(pred - true)))\n",
        "\n",
        "def mape(pred, true):\n",
        "    eps = 1e-8\n",
        "    return float(np.mean(np.abs((true - pred) / (np.abs(true) + eps)))) * 100.0"
      ],
      "metadata": {
        "id": "r9dBIHRcxhxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "def evaluate_model(model, dataloader, scaler, device):\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    trues = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            x = batch['x'].to(device)\n",
        "            y = batch['y'].to(device)\n",
        "            ex = batch['ex'].to(device)\n",
        "            batch_size, tgt_len, n_series = y.size()\n",
        "            dec_in = torch.zeros((batch_size, tgt_len, n_series), device=device)\n",
        "            out, _ = model(x, ex, dec_in, ex)\n",
        "            if isinstance(out, tuple) or isinstance(out, list):\n",
        "                out = out[0]\n",
        "            out_np = out.cpu().numpy()\n",
        "            y_np = y.cpu().numpy()\n",
        "            out_un = scaler.inverse_transform(out_np.reshape(-1, n_series)).reshape(out_np.shape)\n",
        "            y_un = scaler.inverse_transform(y_np.reshape(-1, n_series)).reshape(y_np.shape)\n",
        "            preds.append(out_un)\n",
        "            trues.append(y_un)\n",
        "    preds = np.concatenate(preds, axis=0)\n",
        "    trues = np.concatenate(trues, axis=0)\n",
        "    return preds, trues"
      ],
      "metadata": {
        "id": "vrrnsB8rxncd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "def train_model(model, train_loader, val_loader, scaler, epochs=12, lr=3e-4, device=DEVICE, save_path=\"best_model.pt\"):\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.MSELoss()\n",
        "    best_val = float('inf')\n",
        "    best_path = save_path\n",
        "\n",
        "    print(\"Training started...\\n\")\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for batch in train_loader:\n",
        "            x = batch['x'].to(device)\n",
        "            y = batch['y'].to(device)\n",
        "            ex = batch['ex'].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            dec_in = torch.cat([torch.zeros_like(y[:, :1, :]), y[:, :-1, :]], dim=1)\n",
        "            out, _ = model(x, ex, dec_in, ex)\n",
        "            if isinstance(out, (tuple, list)):\n",
        "                out = out[0]\n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item() * x.size(0)\n",
        "        avg_loss = total_loss / len(train_loader.dataset)\n",
        "        preds_val, trues_val = evaluate_model(model, val_loader, scaler, device)\n",
        "        val_rmse = rmse(preds_val, trues_val)\n",
        "        if val_rmse < best_val:\n",
        "            best_val = val_rmse\n",
        "            torch.save(model.state_dict(), best_path)\n",
        "        print(f\"Epoch {epoch}/{epochs} | Train Loss: {avg_loss:.6f} | Val RMSE: {val_rmse:.6f}\")\n",
        "    print(\"\\nTraining complete! Best model saved to:\", best_path)\n",
        "    model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "    return model, best_path"
      ],
      "metadata": {
        "id": "6xj-iGbNxsXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention plot\n",
        "def plot_attention_weights(attn_weights, title=\"Attention\", savepath=None):\n",
        "    if not attn_weights:\n",
        "        print(\"No attention weights.\")\n",
        "        return\n",
        "    avg_maps = []\n",
        "    for layer_w in attn_weights:\n",
        "        w = layer_w.detach().cpu().numpy()\n",
        "        avg = w.mean(axis=0).mean(axis=0)\n",
        "        avg_maps.append(avg)\n",
        "    n = len(avg_maps)\n",
        "    fig, axes = plt.subplots(1, n, figsize=(4*n,4))\n",
        "    if n==1:\n",
        "        axes=[axes]\n",
        "    for i,ax in enumerate(axes):\n",
        "        im = ax.imshow(avg_maps[i], aspect='auto')\n",
        "        ax.set_title(f\"Layer {i}\")\n",
        "        fig.colorbar(im, ax=ax)\n",
        "    plt.suptitle(title)\n",
        "    if savepath:\n",
        "        plt.savefig(savepath)\n",
        "        print(\"Saved attention plot to\", savepath)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "vw4GvFUXx0Ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTbDVvB6wqdi",
        "outputId": "86f1df4c-fb96-4a71-e97f-7d75e48bcdf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shapes: (5000, 3) (5000, 2)\n",
            "Training started...\n",
            "\n",
            "Epoch 1/12 | Train Loss: 0.255097 | Val RMSE: 207.547409\n",
            "Epoch 2/12 | Train Loss: 0.036009 | Val RMSE: 169.779144\n",
            "Epoch 3/12 | Train Loss: 0.019264 | Val RMSE: 148.421555\n",
            "Epoch 4/12 | Train Loss: 0.014420 | Val RMSE: 162.950531\n",
            "Epoch 5/12 | Train Loss: 0.011359 | Val RMSE: 153.331711\n",
            "Epoch 6/12 | Train Loss: 0.010027 | Val RMSE: 162.299423\n",
            "Epoch 7/12 | Train Loss: 0.009027 | Val RMSE: 159.018921\n",
            "Epoch 8/12 | Train Loss: 0.008007 | Val RMSE: 125.531281\n",
            "Epoch 9/12 | Train Loss: 0.007458 | Val RMSE: 143.008270\n",
            "Epoch 10/12 | Train Loss: 0.006504 | Val RMSE: 159.274399\n",
            "Epoch 11/12 | Train Loss: 0.006045 | Val RMSE: 153.741272\n",
            "Epoch 12/12 | Train Loss: 0.005977 | Val RMSE: 173.187363\n",
            "\n",
            "Training complete! Best model saved to: outputs/best_model.pt\n",
            "Test RMSE: 422.08734130859375 MAE: 402.9371337890625 MAPE: 26.015466451644897\n",
            "Saved attention plot to outputs/dec_cross_attn.png\n",
            "All outputs saved in ./outputs\n"
          ]
        }
      ],
      "source": [
        "# Main (run)\n",
        "def main():\n",
        "    os.makedirs(\"outputs\", exist_ok=True)\n",
        "\n",
        "    # Data\n",
        "    T = 5000\n",
        "    X, exog = generate_synthetic_multivariate(T=T, n_series=3)\n",
        "    print(\"Data shapes:\", X.shape, exog.shape)\n",
        "\n",
        "    # Splits\n",
        "    train_T = int(0.7*T)\n",
        "    val_T = int(0.85*T)\n",
        "\n",
        "    scaler = StandardScaler().fit(X[:train_T])\n",
        "\n",
        "    # Hyperparams\n",
        "    input_len = 96\n",
        "    output_len = 48\n",
        "    batch_size = 128\n",
        "\n",
        "    train_ds = Seq2SeqDataset(X[:train_T], exog[:train_T], input_len, output_len, scaler=scaler)\n",
        "    val_ds = Seq2SeqDataset(X[train_T:val_T], exog[train_T:val_T], input_len, output_len, scaler=scaler)\n",
        "    test_ds = Seq2SeqDataset(X[val_T:], exog[val_T:], input_len, output_len, scaler=scaler)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Model\n",
        "    model = TransformerTimeSeries(n_series=3, n_exog=exog.shape[1], d_model=128, n_heads=4, n_enc_layers=3, n_dec_layers=3, d_ff=256).to(DEVICE)\n",
        "\n",
        "    # Train\n",
        "    model, best_path = train_model(model, train_loader, val_loader, scaler, epochs=12, lr=3e-4, device=DEVICE, save_path=\"outputs/best_model.pt\")\n",
        "\n",
        "    # Evaluate on test\n",
        "    preds, trues = evaluate_model(model, test_loader, scaler, DEVICE)\n",
        "    print(\"Test RMSE:\", rmse(preds, trues), \"MAE:\", mae(preds, trues), \"MAPE:\", mape(preds, trues))\n",
        "\n",
        "    # Attention viz (one batch)\n",
        "    sample = next(iter(test_loader))\n",
        "    x = sample['x'].to(DEVICE); y = sample['y'].to(DEVICE); ex = sample['ex'].to(DEVICE)\n",
        "    dec_in = torch.cat([torch.zeros_like(y[:,:1,:]), y[:, :-1, :]], dim=1)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        out, attn = model(x, ex, dec_in, ex)\n",
        "    attn_save = \"outputs/dec_cross_attn.png\"\n",
        "    if attn and 'dec_cross_attns' in attn and len(attn['dec_cross_attns'])>0:\n",
        "        plot_attention_weights(attn['dec_cross_attns'], title=\"Decoder Cross-Attention\", savepath=attn_save)\n",
        "\n",
        "    # Save summary\n",
        "    report = {'test_metrics': {'rmse': rmse(preds,trues), 'mae': mae(preds,trues), 'mape': mape(preds,trues)}, 'model': best_path}\n",
        "    with open(\"outputs/report.json\", \"w\") as f:\n",
        "        json.dump(report, f, indent=2)\n",
        "\n",
        "    print(\"All outputs saved in ./outputs\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}